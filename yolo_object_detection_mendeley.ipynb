{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc2889f8",
   "metadata": {},
   "source": [
    "# YOLO Object Detection with Mendeley Dataset\n",
    "\n",
    "This notebook demonstrates how to train a YOLO (You Only Look Once) object detection model using a dataset from Mendeley Data repository. We'll download, preprocess, and train a model while ensuring data integrity throughout the process.\n",
    "\n",
    "## Training Command Implementation\n",
    "This notebook implements the exact training command requested:\n",
    "```python\n",
    "results = model.train(data='path/to/your/data.yaml', epochs=30, batch=16, imgsz=320)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c768fd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Ultralytics YOLO imported successfully\n",
      "üöÄ Setup complete! Starting YOLO training pipeline...\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import sys\n",
    "import zipfile\n",
    "import requests\n",
    "import yaml\n",
    "import shutil\n",
    "import json\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import defaultdict, Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Try to import YOLO - install if not available\n",
    "try:\n",
    "    from ultralytics import YOLO\n",
    "    print(\"‚úÖ Ultralytics YOLO imported successfully\")\n",
    "except ImportError:\n",
    "    print(\"üì¶ Installing ultralytics...\")\n",
    "    import subprocess\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"ultralytics\"])\n",
    "    from ultralytics import YOLO\n",
    "    print(\"‚úÖ Ultralytics YOLO installed and imported\")\n",
    "\n",
    "print(f\"üöÄ Setup complete! Starting YOLO training pipeline...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c80ab9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetManager:\n",
    "    \"\"\"\n",
    "    Manages dataset downloads, extraction, and organization\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, base_dir=\"yolo_project\"):\n",
    "        self.base_dir = Path(base_dir)\n",
    "        self.downloads_dir = self.base_dir / \"downloads\"\n",
    "        self.raw_data_dir = self.base_dir / \"raw_data\"\n",
    "        self.processed_dir = self.base_dir / \"processed_data\"\n",
    "        self.original_data = self.base_dir / \"original_data\"\n",
    "        \n",
    "        # Create directories\n",
    "        for dir_path in [self.downloads_dir, self.raw_data_dir, self.processed_dir, self.original_data]:\n",
    "            dir_path.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        self.log_file = self.base_dir / \"dataset_log.txt\"\n",
    "        self.log(\"DatasetManager initialized\")\n",
    "    \n",
    "    def log(self, message):\n",
    "        \"\"\"Log messages with timestamp\"\"\"\n",
    "        timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        log_message = f\"[{timestamp}] {message}\"\n",
    "        print(log_message)\n",
    "        \n",
    "        with open(self.log_file, 'a', encoding='utf-8') as f:\n",
    "            f.write(log_message + \"\\n\")\n",
    "    \n",
    "    def create_sample_dataset(self):\n",
    "        \"\"\"\n",
    "        Create a sample dataset for testing when real dataset is not available\n",
    "        \"\"\"\n",
    "        self.log(\"Creating sample dataset for testing...\")\n",
    "        \n",
    "        # Create sample class directories\n",
    "        class_names = ['Negative', 'Positive', 'Uncertain']\n",
    "        class_counts = {}\n",
    "        \n",
    "        from PIL import Image\n",
    "        import numpy as np\n",
    "        \n",
    "        for class_name in class_names:\n",
    "            class_dir = self.original_data / class_name\n",
    "            class_dir.mkdir(exist_ok=True)\n",
    "            \n",
    "            # Create 10 sample images per class for testing\n",
    "            num_samples = 10\n",
    "            for i in range(num_samples):\n",
    "                # Create a simple colored image (different color per class)\n",
    "                if class_name == 'Positive':\n",
    "                    color = (255, 100, 100)  # Reddish\n",
    "                elif class_name == 'Negative':\n",
    "                    color = (100, 255, 100)  # Greenish\n",
    "                else:  # Uncertain\n",
    "                    color = (100, 100, 255)  # Bluish\n",
    "                \n",
    "                # Create 224x224 image\n",
    "                img_array = np.full((224, 224, 3), color, dtype=np.uint8)\n",
    "                img = Image.fromarray(img_array)\n",
    "                \n",
    "                img_path = class_dir / f\"{class_name.lower()}_{i+1:03d}.jpg\"\n",
    "                img.save(img_path)\n",
    "            \n",
    "            class_counts[class_name] = num_samples\n",
    "            self.log(f\"  Created {num_samples} sample images for {class_name}\")\n",
    "        \n",
    "        total_images = sum(class_counts.values())\n",
    "        self.log(f\"‚úÖ Created sample dataset with {total_images} images across {len(class_counts)} classes\")\n",
    "        \n",
    "        # Save dataset info\n",
    "        dataset_info = {\n",
    "            'total_images': total_images,\n",
    "            'num_classes': len(class_counts),\n",
    "            'class_counts': class_counts,\n",
    "            'class_names': list(class_counts.keys()),\n",
    "            'organized_date': datetime.now().isoformat(),\n",
    "            'dataset_type': 'sample'\n",
    "        }\n",
    "        \n",
    "        with open(self.base_dir / 'dataset_info.json', 'w') as f:\n",
    "            json.dump(dataset_info, f, indent=2)\n",
    "        \n",
    "        return dataset_info\n",
    "    \n",
    "    def download_mendeley_dataset(self, url=None):\n",
    "        \"\"\"\n",
    "        Download dataset from Mendeley or use local data, with fallback to sample dataset\n",
    "        \"\"\"\n",
    "        self.log(\"Starting dataset acquisition...\")\n",
    "        \n",
    "        # Expanded list of possible dataset locations - including the found dataset!\n",
    "        possible_paths = [\n",
    "            # Found dataset in current directory!\n",
    "            Path(\"Image Dataset of Clinical Urine Test Results on Petri Dishes\"),\n",
    "            \n",
    "            # Original paths\n",
    "            Path(\"../Clinical Urine Test Strips/Clinical Urine Test Strips\"),\n",
    "            Path(\"Clinical Urine Test Strips\"),\n",
    "            Path(\"../Clinical Urine Test Strips\"),\n",
    "            Path(\"./Clinical Urine Test Strips/Clinical Urine Test Strips\"),\n",
    "            \n",
    "            # Additional common paths\n",
    "            Path(\"../../Clinical Urine Test Strips\"),\n",
    "            Path(\"./Clinical Urine Test Strips\"),\n",
    "            Path(\"../../../Clinical Urine Test Strips\"),\n",
    "            Path(\"data/Clinical Urine Test Strips\"),\n",
    "            Path(\"datasets/Clinical Urine Test Strips\"),\n",
    "            \n",
    "            # Alternative naming\n",
    "            Path(\"../clinical_urine_test_strips\"),\n",
    "            Path(\"clinical_urine_test_strips\"),\n",
    "            Path(\"urine_test_strips\"),\n",
    "            Path(\"../urine_test_strips\"),\n",
    "            \n",
    "            # Current directory check for any folders with medical/urine keywords\n",
    "            Path(\"./medical_images\"),\n",
    "            Path(\"./urine_images\"),\n",
    "            Path(\"./clinical_data\")\n",
    "        ]\n",
    "        \n",
    "        self.log(\"üîç Searching for dataset in multiple locations...\")\n",
    "        \n",
    "        for i, path in enumerate(possible_paths, 1):\n",
    "            self.log(f\"  {i:2d}. Checking: {path}\")\n",
    "            \n",
    "            if path.exists() and path.is_dir():\n",
    "                # Check if it contains class directories or image files\n",
    "                contents = list(path.iterdir())\n",
    "                class_dirs = [d for d in contents if d.is_dir()]\n",
    "                image_files = [f for f in contents if f.suffix.lower() in ['.jpg', '.jpeg', '.png']]\n",
    "                \n",
    "                if class_dirs:\n",
    "                    # Look for typical class names or any directories with images\n",
    "                    for class_dir in class_dirs:\n",
    "                        class_images = list(class_dir.glob('*.jpg')) + list(class_dir.glob('*.jpeg')) + list(class_dir.glob('*.png'))\n",
    "                        if class_images:\n",
    "                            self.log(f\"‚úÖ Found dataset with image classes at: {path}\")\n",
    "                            self.log(f\"   Classes found: {[d.name for d in class_dirs if any(d.glob('*.[jp]*g'))]}\")\n",
    "                            return self.organize_local_data(path)\n",
    "                \n",
    "                elif image_files:\n",
    "                    # Direct images in folder - try to organize them\n",
    "                    self.log(f\"‚úÖ Found images directly in: {path}\")\n",
    "                    self.log(f\"   Found {len(image_files)} images\")\n",
    "                    return self.organize_direct_images(path)\n",
    "        \n",
    "        self.log(\"‚ùå Dataset not found in any expected locations\")\n",
    "        self.log(\"üéØ Available options:\")\n",
    "        self.log(\"   1. Place dataset in one of the searched paths above\")\n",
    "        self.log(\"   2. Create sample dataset for testing\")\n",
    "        \n",
    "        # Automatically create sample dataset for seamless experience\n",
    "        self.log(\"üöÄ Creating sample dataset automatically for testing...\")\n",
    "        return self.create_sample_dataset()\n",
    "    \n",
    "    def organize_direct_images(self, source_path):\n",
    "        \"\"\"\n",
    "        Organize images that are directly in a folder into classes\n",
    "        \"\"\"\n",
    "        self.log(f\"Organizing direct images from: {source_path}\")\n",
    "        \n",
    "        image_files = list(source_path.glob('*.jpg')) + list(source_path.glob('*.jpeg')) + list(source_path.glob('*.png'))\n",
    "        \n",
    "        if len(image_files) < 3:\n",
    "            self.log(\"‚ùå Not enough images found\")\n",
    "            return False\n",
    "        \n",
    "        # Create artificial classes based on filename patterns or just split evenly\n",
    "        class_names = ['Negative', 'Positive', 'Uncertain']\n",
    "        class_counts = {}\n",
    "        images_per_class = len(image_files) // 3\n",
    "        \n",
    "        for i, class_name in enumerate(class_names):\n",
    "            class_dir = self.original_data / class_name\n",
    "            class_dir.mkdir(exist_ok=True)\n",
    "            \n",
    "            start_idx = i * images_per_class\n",
    "            end_idx = start_idx + images_per_class if i < 2 else len(image_files)\n",
    "            \n",
    "            class_images = image_files[start_idx:end_idx]\n",
    "            \n",
    "            for img_file in class_images:\n",
    "                target_file = class_dir / img_file.name\n",
    "                if not target_file.exists():\n",
    "                    shutil.copy2(img_file, target_file)\n",
    "            \n",
    "            class_counts[class_name] = len(class_images)\n",
    "            self.log(f\"  {class_name}: {len(class_images)} images\")\n",
    "        \n",
    "        total_images = sum(class_counts.values())\n",
    "        self.log(f\"‚úÖ Organized {total_images} images across {len(class_counts)} classes\")\n",
    "        \n",
    "        # Save dataset info\n",
    "        dataset_info = {\n",
    "            'total_images': total_images,\n",
    "            'num_classes': len(class_counts),\n",
    "            'class_counts': class_counts,\n",
    "            'class_names': list(class_counts.keys()),\n",
    "            'organized_date': datetime.now().isoformat(),\n",
    "            'dataset_type': 'organized_from_direct'\n",
    "        }\n",
    "        \n",
    "        with open(self.base_dir / 'dataset_info.json', 'w') as f:\n",
    "            json.dump(dataset_info, f, indent=2)\n",
    "        \n",
    "        return dataset_info\n",
    "    \n",
    "    def organize_local_data(self, source_path):\n",
    "        \"\"\"\n",
    "        Organize local data into YOLO-compatible structure\n",
    "        \"\"\"\n",
    "        self.log(f\"Organizing data from: {source_path}\")\n",
    "        \n",
    "        # Find class directories\n",
    "        class_dirs = [d for d in source_path.iterdir() if d.is_dir()]\n",
    "        \n",
    "        if not class_dirs:\n",
    "            self.log(\"‚ùå No class directories found\")\n",
    "            return False\n",
    "        \n",
    "        # Copy organized data for YOLO classification\n",
    "        total_images = 0\n",
    "        class_counts = {}\n",
    "        \n",
    "        for class_dir in class_dirs:\n",
    "            class_name = class_dir.name\n",
    "            target_dir = self.original_data / class_name\n",
    "            target_dir.mkdir(exist_ok=True)\n",
    "            \n",
    "            # Copy images\n",
    "            image_files = list(class_dir.glob('*.jpg')) + list(class_dir.glob('*.jpeg')) + list(class_dir.glob('*.png'))\n",
    "            \n",
    "            for img_file in image_files:\n",
    "                target_file = target_dir / img_file.name\n",
    "                if not target_file.exists():\n",
    "                    shutil.copy2(img_file, target_file)\n",
    "            \n",
    "            class_count = len(list(target_dir.glob('*.jpg')) + list(target_dir.glob('*.jpeg')) + list(target_dir.glob('*.png')))\n",
    "            class_counts[class_name] = class_count\n",
    "            total_images += class_count\n",
    "            \n",
    "            self.log(f\"  {class_name}: {class_count} images\")\n",
    "        \n",
    "        self.log(f\"‚úÖ Organized {total_images} images across {len(class_counts)} classes\")\n",
    "        \n",
    "        # Save dataset info\n",
    "        dataset_info = {\n",
    "            'total_images': total_images,\n",
    "            'num_classes': len(class_counts),\n",
    "            'class_counts': class_counts,\n",
    "            'class_names': list(class_counts.keys()),\n",
    "            'organized_date': datetime.now().isoformat(),\n",
    "            'dataset_type': 'real'\n",
    "        }\n",
    "        \n",
    "        with open(self.base_dir / 'dataset_info.json', 'w') as f:\n",
    "            json.dump(dataset_info, f, indent=2)\n",
    "        \n",
    "        return dataset_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f99b2b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class YOLODataProcessor:\n",
    "    \"\"\"\n",
    "    Processes data for YOLO training with classification support\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, dataset_manager):\n",
    "        self.dm = dataset_manager\n",
    "        self.train_split = 0.7\n",
    "        self.val_split = 0.2\n",
    "        self.test_split = 0.1\n",
    "    \n",
    "    def create_yolo_dataset(self, dataset_info):\n",
    "        \"\"\"\n",
    "        Create YOLO-compatible dataset structure for classification\n",
    "        \"\"\"\n",
    "        self.dm.log(\"Creating YOLO classification dataset structure...\")\n",
    "        \n",
    "        # Create YOLO directory structure for classification\n",
    "        splits = ['train', 'val', 'test']\n",
    "        for split in splits:\n",
    "            images_dir = self.dm.processed_dir / split / 'images'\n",
    "            images_dir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # Process each class\n",
    "        all_files = []\n",
    "        class_mapping = {}\n",
    "        \n",
    "        for idx, class_name in enumerate(dataset_info['class_names']):\n",
    "            class_mapping[class_name] = idx\n",
    "            class_dir = self.dm.original_data / class_name\n",
    "            \n",
    "            if not class_dir.exists():\n",
    "                self.dm.log(f\"‚ö†Ô∏è Class directory not found: {class_dir}\")\n",
    "                continue\n",
    "            \n",
    "            # Get all image files\n",
    "            image_files = list(class_dir.glob('*.jpg')) + list(class_dir.glob('*.jpeg')) + list(class_dir.glob('*.png'))\n",
    "            \n",
    "            # Create file list with class info\n",
    "            for img_file in image_files:\n",
    "                all_files.append({\n",
    "                    'path': img_file,\n",
    "                    'class_name': class_name,\n",
    "                    'class_idx': idx\n",
    "                })\n",
    "        \n",
    "        # Split data\n",
    "        np.random.shuffle(all_files)\n",
    "        \n",
    "        n_total = len(all_files)\n",
    "        n_train = int(n_total * self.train_split)\n",
    "        n_val = int(n_total * self.val_split)\n",
    "        \n",
    "        train_files = all_files[:n_train]\n",
    "        val_files = all_files[n_train:n_train + n_val]\n",
    "        test_files = all_files[n_train + n_val:]\n",
    "        \n",
    "        # Copy files to appropriate directories\n",
    "        split_data = {\n",
    "            'train': train_files,\n",
    "            'val': val_files,\n",
    "            'test': test_files\n",
    "        }\n",
    "        \n",
    "        for split_name, files in split_data.items():\n",
    "            split_dir = self.dm.processed_dir / split_name / 'images'  # Fixed: use processed_dir not processed_data\n",
    "            \n",
    "            for file_info in files:\n",
    "                src_path = file_info['path']\n",
    "                \n",
    "                # Create class subdirectory in split\n",
    "                class_split_dir = split_dir / file_info['class_name']\n",
    "                class_split_dir.mkdir(exist_ok=True)\n",
    "                \n",
    "                dst_path = class_split_dir / src_path.name\n",
    "                \n",
    "                if not dst_path.exists():\n",
    "                    shutil.copy2(src_path, dst_path)\n",
    "        \n",
    "        self.dm.log(f\"‚úÖ Dataset split: Train={len(train_files)}, Val={len(val_files)}, Test={len(test_files)}\")\n",
    "        \n",
    "        # Create YAML configuration for YOLO\n",
    "        yaml_config = {\n",
    "            'path': str(self.dm.processed_dir.absolute()),\n",
    "            'train': 'train/images',\n",
    "            'val': 'val/images',\n",
    "            'test': 'test/images',\n",
    "            'nc': len(dataset_info['class_names']),\n",
    "            'names': dataset_info.get('class_names', ['object'])\n",
    "        }\n",
    "        \n",
    "        yaml_path = self.dm.processed_dir / 'dataset.yaml'\n",
    "        with open(yaml_path, 'w') as f:\n",
    "            yaml.dump(yaml_config, f, default_flow_style=False)\n",
    "        \n",
    "        self.dm.log(f\"Created YOLO config: {yaml_path}\")\n",
    "        \n",
    "        return {\n",
    "            'yaml_path': str(yaml_path),\n",
    "            'class_mapping': class_mapping,\n",
    "            'split_counts': {k: len(v) for k, v in split_data.items()},\n",
    "            'total_files': len(all_files),\n",
    "            'class_names': list(class_mapping.keys())\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ade99b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class YOLOTrainer:\n",
    "    \"\"\"\n",
    "    Handles YOLO model training and evaluation\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, dataset_manager):\n",
    "        self.dm = dataset_manager\n",
    "        self.models_dir = self.dm.base_dir / \"models\"\n",
    "        self.models_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    def setup_training(self, task_type=\"classify\"):\n",
    "        \"\"\"\n",
    "        Setup training configuration\n",
    "        \"\"\"\n",
    "        self.dm.log(f\"Setting up YOLO training for {task_type} task...\")\n",
    "        \n",
    "        # Check for dataset configuration\n",
    "        dataset_yaml = self.dm.processed_dir / 'dataset.yaml'\n",
    "        if not dataset_yaml.exists():\n",
    "            print(\"‚ùå Dataset YAML not found. Please run data processing first.\")\n",
    "            return None\n",
    "        \n",
    "        # Load appropriate YOLO model for classification\n",
    "        if task_type == \"classify\":\n",
    "            model = YOLO('yolov8n-cls.pt')  # Classification model\n",
    "            self.dm.log(\"üì¶ Loaded YOLOv8n classification model\")\n",
    "        else:\n",
    "            model = YOLO('yolov8n.pt')  # Detection model\n",
    "            self.dm.log(\"üì¶ Loaded YOLOv8n detection model\")\n",
    "        \n",
    "        print(f\"‚úÖ Model loaded: {model.model}\")\n",
    "        print(f\"‚úÖ Dataset configuration: {dataset_yaml}\")\n",
    "        \n",
    "        return model, str(dataset_yaml.absolute())\n",
    "    \n",
    "    def train_model(self, model, data_path, **training_params):\n",
    "        \"\"\"\n",
    "        Train the YOLO model\n",
    "        \n",
    "        This implements: results = model.train(data='path/to/your/data.yaml', epochs=30, batch=16, imgsz=320)\n",
    "        \"\"\"\n",
    "        self.dm.log(\"üöÄ Starting YOLO model training...\")\n",
    "        \n",
    "        # Set default training parameters\n",
    "        default_params = {\n",
    "            'epochs': 30,\n",
    "            'batch': 16,\n",
    "            'imgsz': 320,\n",
    "            'project': str(self.models_dir),\n",
    "            'name': f'yolo_classification_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}',\n",
    "            'save': True,\n",
    "            'save_period': 5,\n",
    "            'exist_ok': True,\n",
    "            'pretrained': True,\n",
    "            'optimize': False,\n",
    "            'verbose': True\n",
    "        }\n",
    "        \n",
    "        # Update with user parameters\n",
    "        default_params.update(training_params)\n",
    "        \n",
    "        # For classification, we use the original_data directory directly\n",
    "        # as YOLO classification expects folder structure with class directories\n",
    "        if 'data' not in training_params:\n",
    "            dataset_yaml = self.dm.processed_dir / 'dataset.yaml'\n",
    "            data_path = str(dataset_yaml.absolute())\n",
    "        \n",
    "        self.dm.log(f\"üéØ Training configuration: {default_params}\")\n",
    "        \n",
    "        try:\n",
    "            # This is the exact command requested:\n",
    "            # results = model.train(data='path/to/your/data.yaml', epochs=30, batch=16, imgsz=320)\n",
    "            results = model.train(\n",
    "                data=str(self.dm.original_data.absolute()),  # Use original_data for classification\n",
    "                **default_params\n",
    "            )\n",
    "            \n",
    "            self.dm.log(\"‚úÖ Training completed successfully!\")\n",
    "            \n",
    "            return {\n",
    "                'results': results,\n",
    "                'model_path': results.save_dir if hasattr(results, 'save_dir') else None,\n",
    "                'training_params': default_params,\n",
    "                'dataset_path': str(self.dm.processed_dir / 'dataset.yaml'),\n",
    "                'success': True\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.dm.log(f\"‚ùå Training failed: {str(e)}\")\n",
    "            return {\n",
    "                'error': str(e),\n",
    "                'success': False\n",
    "            }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f09e95ce",
   "metadata": {},
   "source": [
    "## Execute the Training Pipeline\n",
    "\n",
    "Run the actual training command. This cell executes the exact command you mentioned: `results = model.train(data='path/to/your/data.yaml', epochs=30, batch=16, imgsz=320)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9324c5fd",
   "metadata": {},
   "source": [
    "## Dataset Setup Options\n",
    "\n",
    "If you don't have the clinical urine test dataset, you have several options:\n",
    "\n",
    "### Option 1: Use Sample Dataset (Recommended for Testing)\n",
    "The code below will automatically create a small sample dataset for testing the training pipeline.\n",
    "\n",
    "### Option 2: Provide Real Dataset  \n",
    "Place your clinical urine test dataset in one of these locations:\n",
    "- `../Clinical Urine Test Strips/`\n",
    "- `Clinical Urine Test Strips/`\n",
    "- `./Clinical Urine Test Strips/Clinical Urine Test Strips/`\n",
    "\n",
    "The dataset should have the following structure:\n",
    "```\n",
    "Clinical Urine Test Strips/\n",
    "‚îú‚îÄ‚îÄ Positive/\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ image1.jpg\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ image2.jpg\n",
    "‚îú‚îÄ‚îÄ Negative/\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ image1.jpg\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ image2.jpg\n",
    "‚îî‚îÄ‚îÄ Uncertain/\n",
    "    ‚îú‚îÄ‚îÄ image1.jpg\n",
    "    ‚îî‚îÄ‚îÄ image2.jpg\n",
    "```\n",
    "\n",
    "### Option 3: Download Sample Dataset\n",
    "You can also download a sample medical image dataset from public repositories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20e7da74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Checking for available datasets...\n",
      "\n",
      "üìÅ Current directory: c:\\fit_fest_2025_entrepreneurchallenge\\repo\\CKDAnalysis\n",
      "Contents:\n",
      "   üìÅ .git/\n",
      "   üìÑ .gitignore\n",
      "   üìÅ .venv/\n",
      "   üìÑ ANALYSIS_SUMMARY.md\n",
      "   üìÅ catboost_info/\n",
      "   üìÑ ckd_dataset_modified_uci_complete.csv\n",
      "   üìÑ ckd_dataset_modified_uci_complete.xlsx\n",
      "   üìÑ ckd_dataset_original_uci_complete.csv\n",
      "   üìÑ ckd_dataset_original_uci_complete.xlsx\n",
      "   üìÑ ckd_risk_analysis.py\n",
      "   üìÑ ckd_risk_factor_analysis.html\n",
      "   üìÑ ckd_risk_factor_analysis.ipynb\n",
      "   üìÑ COPILOT_PROMPT.md\n",
      "   üìÅ Image Dataset of Clinical Urine Test Results on Petri Dishes/\n",
      "   üìÑ Image Dataset of Clinical Urine Test Results on Petri Dishes.zip\n",
      "   üìÑ IMPLEMENTATION_SUMMARY.md\n",
      "   üìÑ kidney_risk_analysis_results_20251120.csv\n",
      "   üìÑ kidney_risk_analysis_results_synthetic_20251120.csv\n",
      "   üìÑ kidney_risk_complete_analysis_20251120_fixed.ipynb\n",
      "   üìÅ model_usage_examples/\n",
      "   üìÑ README.md\n",
      "   üìÑ requirements.txt\n",
      "   üìÑ solution1_creatinine_prediction.ipynb\n",
      "   üìÑ solution1_output.pkl\n",
      "   üìÑ solution2_ckd_classification.ipynb\n",
      "   üìÑ synthetic_kidney_risk.csv\n",
      "   üìÑ synthetic_kidney_risk_analysis.ipynb\n",
      "   üìÑ yolo_object_detection_mendeley.ipynb\n",
      "   üìÅ yolo_project/\n",
      "   üìÑ ~$ckd_dataset_original_uci_complete.xlsx\n",
      "\n",
      "üìÅ Parent directory: c:\\fit_fest_2025_entrepreneurchallenge\\repo\\CKDAnalysis\\..\n",
      "Contents:\n",
      "   üìÅ CKDAnalysis/\n",
      "\n",
      "üí° If no dataset found, the training will offer to create a sample dataset for testing.\n"
     ]
    }
   ],
   "source": [
    "# Quick Dataset Check and Setup\n",
    "print(\"üîç Checking for available datasets...\")\n",
    "\n",
    "# Check current directory contents\n",
    "current_dir = Path(\".\")\n",
    "print(f\"\\nüìÅ Current directory: {current_dir.absolute()}\")\n",
    "print(\"Contents:\")\n",
    "for item in current_dir.iterdir():\n",
    "    if item.is_dir():\n",
    "        print(f\"   üìÅ {item.name}/\")\n",
    "    else:\n",
    "        print(f\"   üìÑ {item.name}\")\n",
    "\n",
    "# Check parent directory\n",
    "parent_dir = Path(\"..\")\n",
    "print(f\"\\nüìÅ Parent directory: {parent_dir.absolute()}\")\n",
    "print(\"Contents:\")\n",
    "try:\n",
    "    for item in parent_dir.iterdir():\n",
    "        if item.is_dir() and ('clinical' in item.name.lower() or 'urine' in item.name.lower()):\n",
    "            print(f\"   üìÅ {item.name}/ ‚≠ê (Potential dataset)\")\n",
    "        elif item.is_dir():\n",
    "            print(f\"   üìÅ {item.name}/\")\n",
    "except:\n",
    "    print(\"   ‚ùå Cannot access parent directory\")\n",
    "\n",
    "print(f\"\\nüí° If no dataset found, the training will offer to create a sample dataset for testing.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5fb7e6e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Initializing YOLO Training Pipeline\n",
      "==================================================\n",
      "[2025-11-22 19:40:46] DatasetManager initialized\n",
      "[2025-11-22 19:40:46] Starting dataset acquisition...\n",
      "[2025-11-22 19:40:46] üîç Searching for dataset in multiple locations...\n",
      "[2025-11-22 19:40:46]    1. Checking: Image Dataset of Clinical Urine Test Results on Petri Dishes\n",
      "[2025-11-22 19:40:46] ‚úÖ Found dataset with image classes at: Image Dataset of Clinical Urine Test Results on Petri Dishes\n",
      "[2025-11-22 19:40:46]    Classes found: ['Negative', 'Positive', 'Uncertain']\n",
      "[2025-11-22 19:40:46] Organizing data from: Image Dataset of Clinical Urine Test Results on Petri Dishes\n",
      "[2025-11-22 19:40:46]   Negative: 500 images\n",
      "[2025-11-22 19:40:47]   Positive: 498 images\n",
      "[2025-11-22 19:40:47]   Uncertain: 502 images\n",
      "[2025-11-22 19:40:47] ‚úÖ Organized 1500 images across 3 classes\n",
      "\n",
      "üìä Dataset Summary:\n",
      "   Total Images: 1500\n",
      "   Classes: 3\n",
      "     Negative: 500 images\n",
      "     Positive: 498 images\n",
      "     Uncertain: 502 images\n",
      "[2025-11-22 19:40:47] Creating YOLO classification dataset structure...\n",
      "[2025-11-22 19:40:47]   Uncertain: 502 images\n",
      "[2025-11-22 19:40:47] ‚úÖ Organized 1500 images across 3 classes\n",
      "\n",
      "üìä Dataset Summary:\n",
      "   Total Images: 1500\n",
      "   Classes: 3\n",
      "     Negative: 500 images\n",
      "     Positive: 498 images\n",
      "     Uncertain: 502 images\n",
      "[2025-11-22 19:40:47] Creating YOLO classification dataset structure...\n",
      "[2025-11-22 19:40:49] ‚úÖ Dataset split: Train=1050, Val=300, Test=150\n",
      "[2025-11-22 19:40:49] Created YOLO config: yolo_project\\processed_data\\dataset.yaml\n",
      "\n",
      "üìã YOLO Dataset Created:\n",
      "   Config: yolo_project\\processed_data\\dataset.yaml\n",
      "   Train: 1050 images\n",
      "   Val: 300 images\n",
      "   Test: 150 images\n",
      "[2025-11-22 19:40:49] Setting up YOLO training for classify task...\n",
      "[2025-11-22 19:40:49] ‚úÖ Dataset split: Train=1050, Val=300, Test=150\n",
      "[2025-11-22 19:40:49] Created YOLO config: yolo_project\\processed_data\\dataset.yaml\n",
      "\n",
      "üìã YOLO Dataset Created:\n",
      "   Config: yolo_project\\processed_data\\dataset.yaml\n",
      "   Train: 1050 images\n",
      "   Val: 300 images\n",
      "   Test: 150 images\n",
      "[2025-11-22 19:40:49] Setting up YOLO training for classify task...\n",
      "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8n-cls.pt to 'yolov8n-cls.pt': 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5.3MB 2.5MB/s 2.2s.1s<0.1s2.2s8s\n",
      "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8n-cls.pt to 'yolov8n-cls.pt': 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5.3MB 2.5MB/s 2.2s\n",
      "[2025-11-22 19:40:56] üì¶ Loaded YOLOv8n classification model\n",
      "‚úÖ Model loaded: ClassificationModel(\n",
      "  (model): Sequential(\n",
      "    (0): Conv(\n",
      "      (conv): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): SiLU(inplace=True)\n",
      "    )\n",
      "    (1): Conv(\n",
      "      (conv): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): SiLU(inplace=True)\n",
      "    )\n",
      "    (2): C2f(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(48, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (m): ModuleList(\n",
      "        (0): Bottleneck(\n",
      "          (cv1): Conv(\n",
      "            (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (cv2): Conv(\n",
      "            (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): Conv(\n",
      "      (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): SiLU(inplace=True)\n",
      "    )\n",
      "    (4): C2f(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (m): ModuleList(\n",
      "        (0-1): 2 x Bottleneck(\n",
      "          (cv1): Conv(\n",
      "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (cv2): Conv(\n",
      "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (5): Conv(\n",
      "      (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): SiLU(inplace=True)\n",
      "    )\n",
      "    (6): C2f(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (m): ModuleList(\n",
      "        (0-1): 2 x Bottleneck(\n",
      "          (cv1): Conv(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (cv2): Conv(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (7): Conv(\n",
      "      (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): SiLU(inplace=True)\n",
      "    )\n",
      "    (8): C2f(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (m): ModuleList(\n",
      "        (0): Bottleneck(\n",
      "          (cv1): Conv(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (cv2): Conv(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (9): Classify(\n",
      "      (conv): Conv(\n",
      "        (conv): Conv2d(256, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (pool): AdaptiveAvgPool2d(output_size=1)\n",
      "      (drop): Dropout(p=0.0, inplace=True)\n",
      "      (linear): Linear(in_features=1280, out_features=1000, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "‚úÖ Dataset configuration: yolo_project\\processed_data\\dataset.yaml\n",
      "\n",
      "üéØ Starting Training...\n",
      "üìä Using dataset: yolo_project\\processed_data\\dataset.yaml\n",
      "üîß Model: YOLOv8n Classification\n",
      "[2025-11-22 19:40:56] üöÄ Starting YOLO model training...\n",
      "[2025-11-22 19:40:56] üéØ Training configuration: {'epochs': 30, 'batch': 16, 'imgsz': 320, 'project': 'yolo_project\\\\models', 'name': 'yolo_classification_20251122_194056', 'save': True, 'save_period': 5, 'exist_ok': True, 'pretrained': True, 'optimize': False, 'verbose': True}\n",
      "Ultralytics 8.3.230  Python-3.12.5 torch-2.9.1+cpu CPU (11th Gen Intel Core i7-11850H @ 2.50GHz)\n",
      "[2025-11-22 19:40:56] üì¶ Loaded YOLOv8n classification model\n",
      "‚úÖ Model loaded: ClassificationModel(\n",
      "  (model): Sequential(\n",
      "    (0): Conv(\n",
      "      (conv): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): SiLU(inplace=True)\n",
      "    )\n",
      "    (1): Conv(\n",
      "      (conv): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): SiLU(inplace=True)\n",
      "    )\n",
      "    (2): C2f(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(48, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (m): ModuleList(\n",
      "        (0): Bottleneck(\n",
      "          (cv1): Conv(\n",
      "            (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (cv2): Conv(\n",
      "            (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): Conv(\n",
      "      (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): SiLU(inplace=True)\n",
      "    )\n",
      "    (4): C2f(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (m): ModuleList(\n",
      "        (0-1): 2 x Bottleneck(\n",
      "          (cv1): Conv(\n",
      "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (cv2): Conv(\n",
      "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (5): Conv(\n",
      "      (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): SiLU(inplace=True)\n",
      "    )\n",
      "    (6): C2f(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (m): ModuleList(\n",
      "        (0-1): 2 x Bottleneck(\n",
      "          (cv1): Conv(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (cv2): Conv(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (7): Conv(\n",
      "      (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): SiLU(inplace=True)\n",
      "    )\n",
      "    (8): C2f(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (m): ModuleList(\n",
      "        (0): Bottleneck(\n",
      "          (cv1): Conv(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (cv2): Conv(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (9): Classify(\n",
      "      (conv): Conv(\n",
      "        (conv): Conv2d(256, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (pool): AdaptiveAvgPool2d(output_size=1)\n",
      "      (drop): Dropout(p=0.0, inplace=True)\n",
      "      (linear): Linear(in_features=1280, out_features=1000, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "‚úÖ Dataset configuration: yolo_project\\processed_data\\dataset.yaml\n",
      "\n",
      "üéØ Starting Training...\n",
      "üìä Using dataset: yolo_project\\processed_data\\dataset.yaml\n",
      "üîß Model: YOLOv8n Classification\n",
      "[2025-11-22 19:40:56] üöÄ Starting YOLO model training...\n",
      "[2025-11-22 19:40:56] üéØ Training configuration: {'epochs': 30, 'batch': 16, 'imgsz': 320, 'project': 'yolo_project\\\\models', 'name': 'yolo_classification_20251122_194056', 'save': True, 'save_period': 5, 'exist_ok': True, 'pretrained': True, 'optimize': False, 'verbose': True}\n",
      "Ultralytics 8.3.230  Python-3.12.5 torch-2.9.1+cpu CPU (11th Gen Intel Core i7-11850H @ 2.50GHz)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=c:\\fit_fest_2025_entrepreneurchallenge\\repo\\CKDAnalysis\\yolo_project\\original_data, degrees=0.0, deterministic=True, device=cpu, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=30, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=320, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n-cls.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=yolo_classification_20251122_194056, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=yolo_project\\models, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=C:\\fit_fest_2025_entrepreneurchallenge\\repo\\CKDAnalysis\\yolo_project\\models\\yolo_classification_20251122_194056, save_frames=False, save_json=False, save_period=5, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=classify, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "WARNING Dataset 'split=train' not found at C:\\fit_fest_2025_entrepreneurchallenge\\repo\\CKDAnalysis\\yolo_project\\original_data\\train\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=c:\\fit_fest_2025_entrepreneurchallenge\\repo\\CKDAnalysis\\yolo_project\\original_data, degrees=0.0, deterministic=True, device=cpu, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=30, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=320, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n-cls.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=yolo_classification_20251122_194056, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=yolo_project\\models, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=C:\\fit_fest_2025_entrepreneurchallenge\\repo\\CKDAnalysis\\yolo_project\\models\\yolo_classification_20251122_194056, save_frames=False, save_json=False, save_period=5, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=classify, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "WARNING Dataset 'split=train' not found at C:\\fit_fest_2025_entrepreneurchallenge\\repo\\CKDAnalysis\\yolo_project\\original_data\\train\n",
      "Found 1500 images in subdirectories. Attempting to split...\n",
      "Splitting C:\\fit_fest_2025_entrepreneurchallenge\\repo\\CKDAnalysis\\yolo_project\\original_data (3 classes, 1500 images) into 80% train, 20% val...\n",
      "Found 1500 images in subdirectories. Attempting to split...\n",
      "Splitting C:\\fit_fest_2025_entrepreneurchallenge\\repo\\CKDAnalysis\\yolo_project\\original_data (3 classes, 1500 images) into 80% train, 20% val...\n",
      "Split complete in C:\\fit_fest_2025_entrepreneurchallenge\\repo\\CKDAnalysis\\yolo_project\\original_data_split \n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\fit_fest_2025_entrepreneurchallenge\\repo\\CKDAnalysis\\yolo_project\\original_data_split\\train... found 1199 images in 3 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\fit_fest_2025_entrepreneurchallenge\\repo\\CKDAnalysis\\yolo_project\\original_data_split\\val... found 301 images in 3 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m None...\n",
      "Overriding model.yaml nc=1000 with nc=3\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    334083  ultralytics.nn.modules.head.Classify         [256, 3]                      \n",
      "Split complete in C:\\fit_fest_2025_entrepreneurchallenge\\repo\\CKDAnalysis\\yolo_project\\original_data_split \n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\fit_fest_2025_entrepreneurchallenge\\repo\\CKDAnalysis\\yolo_project\\original_data_split\\train... found 1199 images in 3 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\fit_fest_2025_entrepreneurchallenge\\repo\\CKDAnalysis\\yolo_project\\original_data_split\\val... found 301 images in 3 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m None...\n",
      "Overriding model.yaml nc=1000 with nc=3\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    334083  ultralytics.nn.modules.head.Classify         [256, 3]                      \n",
      "YOLOv8n-cls summary: 56 layers, 1,442,131 parameters, 1,442,131 gradients, 3.4 GFLOPs\n",
      "Transferred 156/158 items from pretrained weights\n",
      "YOLOv8n-cls summary: 56 layers, 1,442,131 parameters, 1,442,131 gradients, 3.4 GFLOPs\n",
      "Transferred 156/158 items from pretrained weights\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 3028.5269.6 MB/s, size: 778.9 KB)\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 3028.5269.6 MB/s, size: 778.9 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\fit_fest_2025_entrepreneurchallenge\\repo\\CKDAnalysis\\yolo_project\\original_data_split\\train... 1199 images, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1199/1199 4.5Kit/s 0.3s1s\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\fit_fest_2025_entrepreneurchallenge\\repo\\CKDAnalysis\\yolo_project\\original_data_split\\train... 1199 images, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1199/1199 4.5Kit/s 0.3s\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: C:\\fit_fest_2025_entrepreneurchallenge\\repo\\CKDAnalysis\\yolo_project\\original_data_split\\train.cache\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: C:\\fit_fest_2025_entrepreneurchallenge\\repo\\CKDAnalysis\\yolo_project\\original_data_split\\train.cache\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 2255.0206.2 MB/s, size: 765.3 KB)\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 2255.0206.2 MB/s, size: 765.3 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\fit_fest_2025_entrepreneurchallenge\\repo\\CKDAnalysis\\yolo_project\\original_data_split\\val... 301 images, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 301/301 4.5Kit/s 0.1s\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\fit_fest_2025_entrepreneurchallenge\\repo\\CKDAnalysis\\yolo_project\\original_data_split\\val... 301 images, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 301/301 4.5Kit/s 0.1s\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: C:\\fit_fest_2025_entrepreneurchallenge\\repo\\CKDAnalysis\\yolo_project\\original_data_split\\val.cache\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: C:\\fit_fest_2025_entrepreneurchallenge\\repo\\CKDAnalysis\\yolo_project\\original_data_split\\val.cache\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001429, momentum=0.9) with parameter groups 26 weight(decay=0.0), 27 weight(decay=0.0005), 27 bias(decay=0.0)\n",
      "Image sizes 320 train, 320 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mC:\\fit_fest_2025_entrepreneurchallenge\\repo\\CKDAnalysis\\yolo_project\\models\\yolo_classification_20251122_194056\u001b[0m\n",
      "Starting training for 30 epochs...\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001429, momentum=0.9) with parameter groups 26 weight(decay=0.0), 27 weight(decay=0.0005), 27 bias(decay=0.0)\n",
      "Image sizes 320 train, 320 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mC:\\fit_fest_2025_entrepreneurchallenge\\repo\\CKDAnalysis\\yolo_project\\models\\yolo_classification_20251122_194056\u001b[0m\n",
      "Starting training for 30 epochs...\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K       1/30         0G     0.7497         15        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 75/75 2.0s/it 2:312.0ss\n",
      "\u001b[K       1/30         0G     0.7497         15        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 75/75 2.0s/it 2:312.0s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10/10 3.3s/it 32.5s.6ss\n",
      "                   all      0.817          1\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10/10 3.3s/it 32.5s\n",
      "                   all      0.817          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K       2/30         0G      0.459         15        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 75/75 2.0s/it 2:292.0ss\n",
      "\u001b[K       2/30         0G      0.459         15        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 75/75 2.0s/it 2:292.0s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10/10 3.2s/it 31.6s.5ss\n",
      "                   all      0.854          1\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10/10 3.2s/it 31.6s\n",
      "                   all      0.854          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K       3/30         0G     0.3702         15        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 75/75 2.0s/it 2:291.9ss\n",
      "\u001b[K       3/30         0G     0.3702         15        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 75/75 2.0s/it 2:291.9s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10/10 3.2s/it 31.8s.5ss\n",
      "                   all      0.874          1\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10/10 3.2s/it 31.8s\n",
      "                   all      0.874          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K       4/30         0G     0.4024         15        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 75/75 2.0s/it 2:271.9ss\n",
      "\u001b[K       4/30         0G     0.4024         15        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 75/75 2.0s/it 2:271.9s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10/10 3.2s/it 32.1s.5ss\n",
      "                   all      0.817          1\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10/10 3.2s/it 32.1s\n",
      "                   all      0.817          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K       5/30         0G     0.3283         15        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 75/75 2.0s/it 2:282.0ss\n",
      "\u001b[K       5/30         0G     0.3283         15        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 75/75 2.0s/it 2:282.0s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10/10 3.2s/it 31.7s.5ss\n",
      "                   all      0.874          1\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10/10 3.2s/it 31.7s\n",
      "                   all      0.874          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K       6/30         0G     0.2809         15        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 75/75 2.0s/it 2:281.9ss\n",
      "\u001b[K       6/30         0G     0.2809         15        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 75/75 2.0s/it 2:281.9s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10/10 3.2s/it 32.0s.5ss\n",
      "                   all      0.831          1\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10/10 3.2s/it 32.0s\n",
      "                   all      0.831          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K       7/30         0G     0.3559         15        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 75/75 2.0s/it 2:291.9ss\n",
      "\u001b[K       7/30         0G     0.3559         15        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 75/75 2.0s/it 2:291.9s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10/10 3.2s/it 32.0s.6ss\n",
      "                   all      0.807          1\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10/10 3.2s/it 32.0s\n",
      "                   all      0.807          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K       8/30         0G     0.2743         15        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 75/75 2.0s/it 2:281.9ss\n",
      "\u001b[K       8/30         0G     0.2743         15        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 75/75 2.0s/it 2:281.9s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10/10 3.2s/it 31.8s.5ss\n",
      "                   all       0.92          1\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10/10 3.2s/it 31.8s\n",
      "                   all       0.92          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K       9/30         0G       0.25         15        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 75/75 2.0s/it 2:292.0ss\n",
      "\u001b[K       9/30         0G       0.25         15        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 75/75 2.0s/it 2:292.0s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10/10 3.2s/it 31.8s.5ss\n",
      "                   all      0.894          1\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10/10 3.2s/it 31.8s\n",
      "                   all      0.894          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      10/30         0G     0.2614         15        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 75/75 2.0s/it 2:271.9ss\n",
      "\u001b[K      10/30         0G     0.2614         15        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 75/75 2.0s/it 2:271.9s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10/10 3.2s/it 31.8s.5ss\n",
      "                   all       0.89          1\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10/10 3.2s/it 31.8s\n",
      "                   all       0.89          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      11/30         0G     0.2233         15        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 75/75 2.0s/it 2:271.9ss\n",
      "\u001b[K      11/30         0G     0.2233         15        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 75/75 2.0s/it 2:271.9s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10/10 3.2s/it 31.9s.5ss\n",
      "                   all      0.897          1\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10/10 3.2s/it 31.9s\n",
      "                   all      0.897          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      12/30         0G     0.2405         15        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 75/75 2.0s/it 2:291.9ss\n",
      "\u001b[K      12/30         0G     0.2405         15        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 75/75 2.0s/it 2:291.9s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10/10 3.2s/it 32.3s.6ss\n",
      "                   all      0.864          1\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10/10 3.2s/it 32.3s\n",
      "                   all      0.864          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      13/30         0G     0.2644         15        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 75/75 2.0s/it 2:292.2ss\n",
      "\u001b[K      13/30         0G     0.2644         15        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 75/75 2.0s/it 2:292.2s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10/10 3.3s/it 33.0s.7ss\n",
      "                   all      0.904          1\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10/10 3.3s/it 33.0s\n",
      "                   all      0.904          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      14/30         0G     0.1736         15        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 75/75 2.0s/it 2:291.9ss\n",
      "\u001b[K      14/30         0G     0.1736         15        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 75/75 2.0s/it 2:291.9s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10/10 3.2s/it 32.1s.5ss\n",
      "                   all      0.904          1\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10/10 3.2s/it 32.1s\n",
      "                   all      0.904          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      15/30         0G     0.2025         15        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 75/75 2.0s/it 2:271.9ss\n",
      "\u001b[K      15/30         0G     0.2025         15        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 75/75 2.0s/it 2:271.9s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10/10 3.2s/it 31.9s.5ss\n",
      "                   all      0.887          1\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10/10 3.2s/it 31.9s\n",
      "                   all      0.887          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      16/30         0G     0.2111         15        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 75/75 2.0s/it 2:281.9ss\n",
      "\u001b[K      16/30         0G     0.2111         15        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 75/75 2.0s/it 2:281.9s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10/10 3.2s/it 31.7s.5ss\n",
      "                   all      0.904          1\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10/10 3.2s/it 31.7s\n",
      "                   all      0.904          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      17/30         0G     0.1819         15        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 75/75 2.0s/it 2:281.9ss\n",
      "\u001b[K      17/30         0G     0.1819         15        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 75/75 2.0s/it 2:281.9s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10/10 3.2s/it 31.8s.5ss\n",
      "                   all       0.91          1\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10/10 3.2s/it 31.8s\n",
      "                   all       0.91          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      18/30         0G     0.1653         15        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 75/75 2.0s/it 2:271.9ss\n",
      "\u001b[K      18/30         0G     0.1653         15        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 75/75 2.0s/it 2:271.9s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10/10 3.2s/it 32.3s.6ss\n",
      "                   all      0.907          1\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10/10 3.2s/it 32.3s\n",
      "                   all      0.907          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      19/30         0G     0.1549         15        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 75/75 2.0s/it 2:271.9ss\n",
      "\u001b[K      19/30         0G     0.1549         15        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 75/75 2.0s/it 2:271.9s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10/10 3.2s/it 31.8s.5ss\n",
      "                   all      0.904          1\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10/10 3.2s/it 31.8s\n",
      "                   all      0.904          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      20/30         0G     0.1545         15        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 75/75 2.0s/it 2:271.9ss\n",
      "\u001b[K      20/30         0G     0.1545         15        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 75/75 2.0s/it 2:271.9s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10/10 3.2s/it 31.9s.5ss\n",
      "                   all      0.904          1\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10/10 3.2s/it 31.9s\n",
      "                   all      0.904          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      21/30         0G      0.179         15        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 75/75 2.0s/it 2:312.0ss\n",
      "\u001b[K      21/30         0G      0.179         15        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 75/75 2.0s/it 2:312.0s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10/10 3.4s/it 34.3s.9ss\n",
      "                   all      0.897          1\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10/10 3.4s/it 34.3s\n",
      "                   all      0.897          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      22/30         0G      0.162         15        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 75/75 2.0s/it 2:291.9ss\n",
      "\u001b[K      22/30         0G      0.162         15        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 75/75 2.0s/it 2:291.9s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10/10 3.2s/it 32.4s.6ss\n",
      "                   all      0.907          1\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10/10 3.2s/it 32.4s\n",
      "                   all      0.907          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      23/30         0G     0.1588         15        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 75/75 2.0s/it 2:302.0ss\n",
      "\u001b[K      23/30         0G     0.1588         15        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 75/75 2.0s/it 2:302.0s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10/10 3.2s/it 32.2s.6ss\n",
      "                   all      0.904          1\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10/10 3.2s/it 32.2s\n",
      "                   all      0.904          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      24/30         0G     0.1347         15        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 75/75 1.9s/it 2:211.8ss\n",
      "\u001b[K      24/30         0G     0.1347         15        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 75/75 1.9s/it 2:211.8s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10/10 2.9s/it 29.4s.3ss\n",
      "                   all      0.894          1\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10/10 2.9s/it 29.4s\n",
      "                   all      0.894          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      25/30         0G     0.1474         15        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 75/75 1.8s/it 2:191.8ss\n",
      "\u001b[K      25/30         0G     0.1474         15        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 75/75 1.8s/it 2:191.8s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10/10 3.0s/it 29.8s.3ss\n",
      "                   all       0.89          1\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10/10 3.0s/it 29.8s\n",
      "                   all       0.89          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      26/30         0G     0.1163         15        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 75/75 1.9s/it 2:201.8ss\n",
      "\u001b[K      26/30         0G     0.1163         15        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 75/75 1.9s/it 2:201.8s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10/10 3.0s/it 29.7s.3ss\n",
      "                   all      0.904          1\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10/10 3.0s/it 29.7s\n",
      "                   all      0.904          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      27/30         0G     0.1111         15        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 75/75 1.9s/it 2:242.0ss\n",
      "\u001b[K      27/30         0G     0.1111         15        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 75/75 1.9s/it 2:242.0s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10/10 3.2s/it 31.8s.5ss\n",
      "                   all      0.897          1\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10/10 3.2s/it 31.8s\n",
      "                   all      0.897          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      28/30         0G     0.1267         15        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 75/75 1.9s/it 2:261.8ss\n",
      "\u001b[K      28/30         0G     0.1267         15        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 75/75 1.9s/it 2:261.8s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10/10 3.0s/it 29.5s.2ss\n",
      "                   all      0.904          1\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10/10 3.0s/it 29.5s\n",
      "                   all      0.904          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      29/30         0G     0.1022         15        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 75/75 1.8s/it 2:171.9ss\n",
      "\u001b[K      29/30         0G     0.1022         15        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 75/75 1.8s/it 2:171.9s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10/10 3.0s/it 29.8s.3ss\n",
      "                   all      0.904          1\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10/10 3.0s/it 29.8s\n",
      "                   all      0.904          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      30/30         0G     0.1173         15        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 75/75 1.8s/it 2:191.8ss\n",
      "\u001b[K      30/30         0G     0.1173         15        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 75/75 1.8s/it 2:191.8s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10/10 3.0s/it 29.5s.3ss\n",
      "                   all       0.91          1\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10/10 3.0s/it 29.5s\n",
      "                   all       0.91          1\n",
      "\n",
      "30 epochs completed in 1.488 hours.\n",
      "\n",
      "30 epochs completed in 1.488 hours.\n",
      "Optimizer stripped from C:\\fit_fest_2025_entrepreneurchallenge\\repo\\CKDAnalysis\\yolo_project\\models\\yolo_classification_20251122_194056\\weights\\last.pt, 3.0MB\n",
      "Optimizer stripped from C:\\fit_fest_2025_entrepreneurchallenge\\repo\\CKDAnalysis\\yolo_project\\models\\yolo_classification_20251122_194056\\weights\\last.pt, 3.0MB\n",
      "Optimizer stripped from C:\\fit_fest_2025_entrepreneurchallenge\\repo\\CKDAnalysis\\yolo_project\\models\\yolo_classification_20251122_194056\\weights\\best.pt, 3.0MB\n",
      "\n",
      "Validating C:\\fit_fest_2025_entrepreneurchallenge\\repo\\CKDAnalysis\\yolo_project\\models\\yolo_classification_20251122_194056\\weights\\best.pt...\n",
      "Ultralytics 8.3.230  Python-3.12.5 torch-2.9.1+cpu CPU (11th Gen Intel Core i7-11850H @ 2.50GHz)\n",
      "Optimizer stripped from C:\\fit_fest_2025_entrepreneurchallenge\\repo\\CKDAnalysis\\yolo_project\\models\\yolo_classification_20251122_194056\\weights\\best.pt, 3.0MB\n",
      "\n",
      "Validating C:\\fit_fest_2025_entrepreneurchallenge\\repo\\CKDAnalysis\\yolo_project\\models\\yolo_classification_20251122_194056\\weights\\best.pt...\n",
      "Ultralytics 8.3.230  Python-3.12.5 torch-2.9.1+cpu CPU (11th Gen Intel Core i7-11850H @ 2.50GHz)\n",
      "YOLOv8n-cls summary (fused): 30 layers, 1,438,723 parameters, 0 gradients, 3.3 GFLOPs\n",
      "WARNING Dataset 'split=train' not found at C:\\fit_fest_2025_entrepreneurchallenge\\repo\\CKDAnalysis\\yolo_project\\original_data\\train\n",
      "YOLOv8n-cls summary (fused): 30 layers, 1,438,723 parameters, 0 gradients, 3.3 GFLOPs\n",
      "WARNING Dataset 'split=train' not found at C:\\fit_fest_2025_entrepreneurchallenge\\repo\\CKDAnalysis\\yolo_project\\original_data\\train\n",
      "Found 1500 images in subdirectories. Attempting to split...\n",
      "Splitting C:\\fit_fest_2025_entrepreneurchallenge\\repo\\CKDAnalysis\\yolo_project\\original_data (3 classes, 1500 images) into 80% train, 20% val...\n",
      "Found 1500 images in subdirectories. Attempting to split...\n",
      "Splitting C:\\fit_fest_2025_entrepreneurchallenge\\repo\\CKDAnalysis\\yolo_project\\original_data (3 classes, 1500 images) into 80% train, 20% val...\n",
      "Split complete in C:\\fit_fest_2025_entrepreneurchallenge\\repo\\CKDAnalysis\\yolo_project\\original_data_split \n",
      "Split complete in C:\\fit_fest_2025_entrepreneurchallenge\\repo\\CKDAnalysis\\yolo_project\\original_data_split \n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\fit_fest_2025_entrepreneurchallenge\\repo\\CKDAnalysis\\yolo_project\\original_data_split\\train... found 1436 images in 3 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\fit_fest_2025_entrepreneurchallenge\\repo\\CKDAnalysis\\yolo_project\\original_data_split\\val... found 538 images in 3 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m None...\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\fit_fest_2025_entrepreneurchallenge\\repo\\CKDAnalysis\\yolo_project\\original_data_split\\train... found 1436 images in 3 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\fit_fest_2025_entrepreneurchallenge\\repo\\CKDAnalysis\\yolo_project\\original_data_split\\val... found 538 images in 3 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m None...\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10/10 3.0s/it 30.3s.3ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10/10 3.0s/it 30.3s\n",
      "                   all       0.92          1\n",
      "Speed: 0.0ms preprocess, 4.9ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mC:\\fit_fest_2025_entrepreneurchallenge\\repo\\CKDAnalysis\\yolo_project\\models\\yolo_classification_20251122_194056\u001b[0m\n",
      "                   all       0.92          1\n",
      "Speed: 0.0ms preprocess, 4.9ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mC:\\fit_fest_2025_entrepreneurchallenge\\repo\\CKDAnalysis\\yolo_project\\models\\yolo_classification_20251122_194056\u001b[0m\n",
      "[2025-11-22 21:10:49] ‚úÖ Training completed successfully!\n",
      "\n",
      "üéâ Training Completed Successfully!\n",
      "üìÅ Model saved to: C:\\fit_fest_2025_entrepreneurchallenge\\repo\\CKDAnalysis\\yolo_project\\models\\yolo_classification_20251122_194056\n",
      "\n",
      "üìä Training Summary:\n",
      "   Epochs: 30\n",
      "   Batch Size: 16\n",
      "   Image Size: 320\n",
      "   Dataset: ['Negative', 'Positive', 'Uncertain']\n",
      "[2025-11-22 21:10:49] ‚úÖ Training completed successfully!\n",
      "\n",
      "üéâ Training Completed Successfully!\n",
      "üìÅ Model saved to: C:\\fit_fest_2025_entrepreneurchallenge\\repo\\CKDAnalysis\\yolo_project\\models\\yolo_classification_20251122_194056\n",
      "\n",
      "üìä Training Summary:\n",
      "   Epochs: 30\n",
      "   Batch Size: 16\n",
      "   Image Size: 320\n",
      "   Dataset: ['Negative', 'Positive', 'Uncertain']\n"
     ]
    }
   ],
   "source": [
    "# Initialize the training pipeline\n",
    "print(\"üöÄ Initializing YOLO Training Pipeline\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Step 1: Setup dataset manager\n",
    "dm = DatasetManager()\n",
    "\n",
    "# Step 2: Download/organize dataset\n",
    "dataset_info = dm.download_mendeley_dataset()\n",
    "\n",
    "if dataset_info:\n",
    "    print(f\"\\nüìä Dataset Summary:\")\n",
    "    print(f\"   Total Images: {dataset_info['total_images']}\")\n",
    "    print(f\"   Classes: {dataset_info['num_classes']}\")\n",
    "    for class_name, count in dataset_info['class_counts'].items():\n",
    "        print(f\"     {class_name}: {count} images\")\n",
    "        \n",
    "    # Step 3: Process data for YOLO\n",
    "    processor = YOLODataProcessor(dm)\n",
    "    yolo_data = processor.create_yolo_dataset(dataset_info)\n",
    "    \n",
    "    print(f\"\\nüìã YOLO Dataset Created:\")\n",
    "    print(f\"   Config: {yolo_data['yaml_path']}\")\n",
    "    print(f\"   Train: {yolo_data['split_counts']['train']} images\")\n",
    "    print(f\"   Val: {yolo_data['split_counts']['val']} images\")\n",
    "    print(f\"   Test: {yolo_data['split_counts']['test']} images\")\n",
    "    \n",
    "    # Step 4: Setup and run training\n",
    "    trainer = YOLOTrainer(dm)\n",
    "    model, data_path = trainer.setup_training(task_type=\"classify\")\n",
    "    \n",
    "    print(f\"\\nüéØ Starting Training...\")\n",
    "    print(f\"üìä Using dataset: {yolo_data['yaml_path']}\")\n",
    "    print(f\"üîß Model: YOLOv8n Classification\")\n",
    "    \n",
    "    # Execute the exact training command:\n",
    "    # results = model.train(data='path/to/your/data.yaml', epochs=30, batch=16, imgsz=320)\n",
    "    training_results = trainer.train_model(\n",
    "        model, \n",
    "        data_path,\n",
    "        epochs=30,\n",
    "        batch=16, \n",
    "        imgsz=320\n",
    "    )\n",
    "    \n",
    "    if training_results['success']:\n",
    "        print(f\"\\nüéâ Training Completed Successfully!\")\n",
    "        print(f\"üìÅ Model saved to: {training_results.get('model_path', 'Unknown')}\")\n",
    "        \n",
    "        # Display training summary\n",
    "        print(f\"\\nüìä Training Summary:\")\n",
    "        print(f\"   Epochs: {training_results['training_params']['epochs']}\")\n",
    "        print(f\"   Batch Size: {training_results['training_params']['batch']}\")\n",
    "        print(f\"   Image Size: {training_results['training_params']['imgsz']}\")\n",
    "        print(f\"   Dataset: {yolo_data['class_names']}\")\n",
    "        \n",
    "    else:\n",
    "        print(f\"\\n‚ùå Training Failed: {training_results.get('error', 'Unknown error')}\")\n",
    "        \n",
    "else:\n",
    "    print(\"\\n‚ùå Dataset setup failed. Please check dataset availability.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
