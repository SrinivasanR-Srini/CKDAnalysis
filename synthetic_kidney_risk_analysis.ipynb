# Synthetic Kidney Risk Analysis

## Section 1: Introduction and Setup

### Objectives
- To perform a comprehensive analysis of kidney disease risk using the synthetic_kidney_risk.csv dataset.

### Dataset Description
- The dataset contains various features related to kidney health that will help in predicting the risk category of patients. 

```python
# Import necessary libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.svm import SVC
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score

# Set random seed for reproducibility
np.random.seed(42)

# Set plotting styles
sns.set(style='whitegrid')
```

## Section 2: Data Loading and Exploration
```python
# Load synthetic_kidney_risk.csv
data = pd.read_csv('synthetic_kidney_risk.csv')

# Display dataset shape, columns, first rows
data_shape = data.shape
data_columns = data.columns.tolist()
data_head = data.head()

# Check data types and missing values
data_types = data.dtypes
missing_values = data.isnull().sum()

# Display basic statistics
basic_stats = data.describe()
```

## Section 3: Exploratory Data Analysis (EDA)
```python
# Distribution plots for numerical features
numerical_features = ['Age', 'Urine_Creatinine_mg_dL', 'Urine_Albumin_mg_L', 'ACR_mg_per_g', 'pH', 'Specific_Gravity', 'Serum_Creatinine_mg_dL']
for feature in numerical_features:
    sns.histplot(data[feature], kde=True)
    plt.title(f'Distribution of {feature}')
    plt.show()

# Count plots for categorical features
categorical_features = ['Sex', 'Hypertension', 'Diabetes', 'Risk_Category']
for feature in categorical_features:
    sns.countplot(x=data[feature])
    plt.title(f'Count of {feature}')
    plt.show()

# Correlation heatmap
plt.figure(figsize=(10, 8))
sns.heatmap(data.corr(), annot=True, fmt='.2f', cmap='coolwarm')
plt.title('Correlation Heatmap')
plt.show()

# Box plots for feature distributions by Risk_Category
for feature in numerical_features:
    sns.boxplot(x='Risk_Category', y=feature, data=data)
    plt.title(f'{feature} by Risk Category')
    plt.show()

# Scatter plots of key relationships
sns.scatterplot(x='S_ACR', y='S_ML', hue='Risk_Category', data=data)
plt.title('S_ACR vs S_ML')
plt.show()
```

## Section 4: Feature Engineering and Preprocessing
```python
# Encode categorical variables (Sex: M=1, F=0)
data['Sex'] = data['Sex'].map({'M': 1, 'F': 0})

# Verify derived scores
# Assuming scores are already calculated in the dataset

# Create feature matrix X and target y
X = data[['Age', 'Sex', 'Hypertension', 'Diabetes', 'Urine_Creatinine_mg_dL', 'Urine_Albumin_mg_L', 'ACR_mg_per_g', 'pH', 'Specific_Gravity', 'Serum_Creatinine_mg_dL']]
y = data['Risk_Category']

# Split data into train/test sets (80/20)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Apply StandardScaler to numerical features
from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)
```

## Section 5: Model Training - Multi-class Classification
```python
# Define hyperparameter grids for models
rf_param_grid = {'n_estimators': [50, 100], 'max_depth': [None, 10, 20]}

# Random Forest Classifier with GridSearchCV
rf_model = GridSearchCV(RandomForestClassifier(), param_grid=rf_param_grid, cv=5)
rf_model.fit(X_train_scaled, y_train)

# Evaluate model
rf_preds = rf_model.predict(X_test_scaled)
print("Random Forest Classifier Results:")
print(classification_report(y_test, rf_preds))

# Continue this structure for other models (Gradient Boosting, SVM, Logistic Regression)
```

## Section 6: Model Comparison and Visualization
```python
# Create a comparison table of all models with accuracy, precision, recall, f1-score
# Bar plots comparing metrics
# ROC curves for each model (one-vs-rest for multi-class)
# Feature importance analysis
```

## Section 7: Formula Verification and Analysis
```python
# Verify the composite score formula
# Show examples of score calculations
# Analyze relationship between S_ACR, S_ML, and final Risk_Category
```

## Section 8: Advanced Analysis
```python
# Permutation importance for top model
# Partial dependence plots for key features
# SHAP values (if applicable)
# Error analysis - examine misclassified cases
```

## Section 9: Conclusions and Recommendations
```python
# Summary of best performing model
# Key findings about risk factors
# Feature importance insights
# Model deployment recommendations
```