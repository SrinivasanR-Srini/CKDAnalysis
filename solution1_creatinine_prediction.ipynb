{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solution 1: Creatinine Prediction\n",
    "## Objective: Predict serum creatinine levels using selected features\n",
    "\n",
    "### Features Used:\n",
    "- Age\n",
    "- Albumin (urine)\n",
    "- RBC (Red Blood Cells - nominal)\n",
    "- Pus Cell (nominal)\n",
    "- Bacteria (nominal)\n",
    "- Urine pH\n",
    "\n",
    "### Models:\n",
    "1. Perceptron (baseline)\n",
    "2. XGBoost (ensemble)\n",
    "3. CatBoost (ensemble)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from xgboost import XGBRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Initial Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset from UCI repository\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00336/chronic_kidney_disease.arff\"\n",
    "\n",
    "# Since it's an ARFF file, we'll use scipy or manually parse it\n",
    "from scipy.io import arff\n",
    "import io\n",
    "import requests\n",
    "\n",
    "# Download and load the ARFF file\n",
    "response = requests.get(url)\n",
    "data, meta = arff.loadarff(io.BytesIO(response.content))\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Decode byte strings to regular strings\n",
    "for col in df.columns:\n",
    "    if df[col].dtype == object:\n",
    "        df[col] = df[col].str.decode('utf-8')\n",
    "\n",
    "print(\"Dataset Shape:\", df.shape)\n",
    "print(\"\\nFirst few rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display dataset information\n",
    "print(\"Dataset Info:\")\n",
    "df.info()\n",
    "print(\"\\nColumn Names:\")\n",
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display statistical summary\n",
    "print(\"Statistical Summary:\")\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Feature Selection and Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select required features based on specification\n",
    "# Features: Age, Albumin (al - urine), RBC (rbc), Pus Cell (pc), Bacteria (ba), pH (ph)\n",
    "# Target: Serum Creatinine (sc)\n",
    "\n",
    "selected_features = ['age', 'al', 'rbc', 'pc', 'ba', 'ph']\n",
    "target = 'sc'\n",
    "\n",
    "# Create working dataframe with selected features and target\n",
    "df_work = df[selected_features + [target]].copy()\n",
    "\n",
    "print(\"Working Dataset Shape:\", df_work.shape)\n",
    "print(\"\\nMissing Values:\")\n",
    "print(df_work.isnull().sum())\n",
    "print(\"\\nMissing Values Percentage:\")\n",
    "print((df_work.isnull().sum() / len(df_work)) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for '?' or other missing value indicators\n",
    "print(\"Checking for '?' or '\\\\t?' values:\")\n",
    "for col in df_work.columns:\n",
    "    if df_work[col].dtype == object:\n",
    "        unique_vals = df_work[col].unique()\n",
    "        print(f\"\\n{col}: {unique_vals}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace missing value indicators with NaN\n",
    "df_work = df_work.replace(['?', '\\t?', ' ?', '? '], np.nan)\n",
    "\n",
    "# Convert numeric columns to appropriate types\n",
    "numeric_cols = ['age', 'al', 'ph', 'sc']\n",
    "for col in numeric_cols:\n",
    "    df_work[col] = pd.to_numeric(df_work[col], errors='coerce')\n",
    "\n",
    "print(\"Missing Values After Conversion:\")\n",
    "print(df_work.isnull().sum())\n",
    "print(\"\\nData Types:\")\n",
    "print(df_work.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing values\n",
    "# For numeric features: impute with median\n",
    "# For categorical features: impute with mode\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Numeric imputation\n",
    "numeric_imputer = SimpleImputer(strategy='median')\n",
    "df_work[numeric_cols] = numeric_imputer.fit_transform(df_work[numeric_cols])\n",
    "\n",
    "# Categorical imputation\n",
    "categorical_cols = ['rbc', 'pc', 'ba']\n",
    "categorical_imputer = SimpleImputer(strategy='most_frequent')\n",
    "df_work[categorical_cols] = categorical_imputer.fit_transform(df_work[categorical_cols].values.reshape(-1, len(categorical_cols)))\n",
    "\n",
    "print(\"Missing Values After Imputation:\")\n",
    "print(df_work.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of target variable (Serum Creatinine)\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.hist(df_work['sc'], bins=30, edgecolor='black', alpha=0.7)\n",
    "plt.xlabel('Serum Creatinine (mg/dL)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Serum Creatinine')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.boxplot(df_work['sc'])\n",
    "plt.ylabel('Serum Creatinine (mg/dL)')\n",
    "plt.title('Box Plot of Serum Creatinine')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "from scipy import stats\n",
    "stats.probplot(df_work['sc'], dist=\"norm\", plot=plt)\n",
    "plt.title('Q-Q Plot of Serum Creatinine')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Target Variable Statistics:\")\n",
    "print(df_work['sc'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of numeric features\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "axes[0, 0].hist(df_work['age'], bins=20, edgecolor='black', alpha=0.7, color='skyblue')\n",
    "axes[0, 0].set_xlabel('Age (years)')\n",
    "axes[0, 0].set_ylabel('Frequency')\n",
    "axes[0, 0].set_title('Distribution of Age')\n",
    "\n",
    "axes[0, 1].hist(df_work['al'], bins=20, edgecolor='black', alpha=0.7, color='lightcoral')\n",
    "axes[0, 1].set_xlabel('Albumin (urine)')\n",
    "axes[0, 1].set_ylabel('Frequency')\n",
    "axes[0, 1].set_title('Distribution of Albumin')\n",
    "\n",
    "axes[1, 0].hist(df_work['ph'], bins=20, edgecolor='black', alpha=0.7, color='lightgreen')\n",
    "axes[1, 0].set_xlabel('Urine pH')\n",
    "axes[1, 0].set_ylabel('Frequency')\n",
    "axes[1, 0].set_title('Distribution of Urine pH')\n",
    "\n",
    "# Categorical feature distribution\n",
    "categorical_counts = pd.DataFrame({\n",
    "    'RBC': df_work['rbc'].value_counts(),\n",
    "    'Pus Cell': df_work['pc'].value_counts(),\n",
    "    'Bacteria': df_work['ba'].value_counts()\n",
    "})\n",
    "categorical_counts.plot(kind='bar', ax=axes[1, 1], alpha=0.7)\n",
    "axes[1, 1].set_ylabel('Count')\n",
    "axes[1, 1].set_title('Distribution of Categorical Features')\n",
    "axes[1, 1].legend(title='Features')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation analysis for numeric features\n",
    "numeric_features = ['age', 'al', 'ph', 'sc']\n",
    "correlation_matrix = df_work[numeric_features].corr()\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, \n",
    "            square=True, linewidths=1, cbar_kws={\"shrink\": 0.8})\n",
    "plt.title('Correlation Matrix of Numeric Features')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nCorrelation with Target (Serum Creatinine):\")\n",
    "print(correlation_matrix['sc'].sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plots: Numeric features vs Target\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "axes[0].scatter(df_work['age'], df_work['sc'], alpha=0.5, color='blue')\n",
    "axes[0].set_xlabel('Age (years)')\n",
    "axes[0].set_ylabel('Serum Creatinine (mg/dL)')\n",
    "axes[0].set_title('Age vs Serum Creatinine')\n",
    "\n",
    "axes[1].scatter(df_work['al'], df_work['sc'], alpha=0.5, color='red')\n",
    "axes[1].set_xlabel('Albumin (urine)')\n",
    "axes[1].set_ylabel('Serum Creatinine (mg/dL)')\n",
    "axes[1].set_title('Albumin vs Serum Creatinine')\n",
    "\n",
    "axes[2].scatter(df_work['ph'], df_work['sc'], alpha=0.5, color='green')\n",
    "axes[2].set_xlabel('Urine pH')\n",
    "axes[2].set_ylabel('Serum Creatinine (mg/dL)')\n",
    "axes[2].set_title('Urine pH vs Serum Creatinine')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box plots: Categorical features vs Target\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "df_work.boxplot(column='sc', by='rbc', ax=axes[0])\n",
    "axes[0].set_xlabel('RBC')\n",
    "axes[0].set_ylabel('Serum Creatinine (mg/dL)')\n",
    "axes[0].set_title('RBC vs Serum Creatinine')\n",
    "\n",
    "df_work.boxplot(column='sc', by='pc', ax=axes[1])\n",
    "axes[1].set_xlabel('Pus Cell')\n",
    "axes[1].set_ylabel('Serum Creatinine (mg/dL)')\n",
    "axes[1].set_title('Pus Cell vs Serum Creatinine')\n",
    "\n",
    "df_work.boxplot(column='sc', by='ba', ax=axes[2])\n",
    "axes[2].set_xlabel('Bacteria')\n",
    "axes[2].set_ylabel('Serum Creatinine (mg/dL)')\n",
    "axes[2].set_title('Bacteria vs Serum Creatinine')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Feature Engineering and Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical features\n",
    "label_encoders = {}\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    df_work[col + '_encoded'] = le.fit_transform(df_work[col])\n",
    "    label_encoders[col] = le\n",
    "    print(f\"\\n{col} encoding:\")\n",
    "    for i, label in enumerate(le.classes_):\n",
    "        print(f\"  {label} -> {i}\")\n",
    "\n",
    "# Create final feature set\n",
    "feature_columns = ['age', 'al', 'ph', 'rbc_encoded', 'pc_encoded', 'ba_encoded']\n",
    "X = df_work[feature_columns].copy()\n",
    "y = df_work['sc'].copy()\n",
    "\n",
    "print(\"\\nFeature Matrix Shape:\", X.shape)\n",
    "print(\"Target Vector Shape:\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Training Set Size:\", X_train.shape)\n",
    "print(\"Test Set Size:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature scaling (important for Perceptron)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"Scaled Training Set Shape:\", X_train_scaled.shape)\n",
    "print(\"Scaled Test Set Shape:\", X_test_scaled.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Training and Evaluation\n",
    "### 5.1 Perceptron Model (Baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Perceptron model\n",
    "# Note: Perceptron is typically for classification, but we'll adapt it for regression\n",
    "# We'll use MLPRegressor instead, which is a neural network (Perceptron-based)\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "perceptron_model = MLPRegressor(\n",
    "    hidden_layer_sizes=(1,),  # Single neuron (perceptron)\n",
    "    activation='identity',     # Linear activation for regression\n",
    "    solver='sgd',              # Stochastic gradient descent\n",
    "    max_iter=1000,\n",
    "    random_state=42,\n",
    "    early_stopping=True,\n",
    "    validation_fraction=0.1\n",
    ")\n",
    "\n",
    "perceptron_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_perceptron_train = perceptron_model.predict(X_train_scaled)\n",
    "y_pred_perceptron_test = perceptron_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluation metrics\n",
    "print(\"Perceptron Model Performance:\")\n",
    "print(\"\\nTraining Set:\")\n",
    "print(f\"  MSE: {mean_squared_error(y_train, y_pred_perceptron_train):.4f}\")\n",
    "print(f\"  RMSE: {np.sqrt(mean_squared_error(y_train, y_pred_perceptron_train)):.4f}\")\n",
    "print(f\"  MAE: {mean_absolute_error(y_train, y_pred_perceptron_train):.4f}\")\n",
    "print(f\"  R² Score: {r2_score(y_train, y_pred_perceptron_train):.4f}\")\n",
    "\n",
    "print(\"\\nTest Set:\")\n",
    "print(f\"  MSE: {mean_squared_error(y_test, y_pred_perceptron_test):.4f}\")\n",
    "print(f\"  RMSE: {np.sqrt(mean_squared_error(y_test, y_pred_perceptron_test)):.4f}\")\n",
    "print(f\"  MAE: {mean_absolute_error(y_test, y_pred_perceptron_test):.4f}\")\n",
    "print(f\"  R² Score: {r2_score(y_test, y_pred_perceptron_test):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 XGBoost Model (Ensemble)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train XGBoost model\n",
    "xgb_model = XGBRegressor(\n",
    "    n_estimators=100,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=5,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_xgb_train = xgb_model.predict(X_train)\n",
    "y_pred_xgb_test = xgb_model.predict(X_test)\n",
    "\n",
    "# Evaluation metrics\n",
    "print(\"XGBoost Model Performance:\")\n",
    "print(\"\\nTraining Set:\")\n",
    "print(f\"  MSE: {mean_squared_error(y_train, y_pred_xgb_train):.4f}\")\n",
    "print(f\"  RMSE: {np.sqrt(mean_squared_error(y_train, y_pred_xgb_train)):.4f}\")\n",
    "print(f\"  MAE: {mean_absolute_error(y_train, y_pred_xgb_train):.4f}\")\n",
    "print(f\"  R² Score: {r2_score(y_train, y_pred_xgb_train):.4f}\")\n",
    "\n",
    "print(\"\\nTest Set:\")\n",
    "print(f\"  MSE: {mean_squared_error(y_test, y_pred_xgb_test):.4f}\")\n",
    "print(f\"  RMSE: {np.sqrt(mean_squared_error(y_test, y_pred_xgb_test)):.4f}\")\n",
    "print(f\"  MAE: {mean_absolute_error(y_test, y_pred_xgb_test):.4f}\")\n",
    "print(f\"  R² Score: {r2_score(y_test, y_pred_xgb_test):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance from XGBoost\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': feature_columns,\n",
    "    'Importance': xgb_model.feature_importances_\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(feature_importance['Feature'], feature_importance['Importance'])\n",
    "plt.xlabel('Importance')\n",
    "plt.title('XGBoost Feature Importance')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nFeature Importance:\")\n",
    "print(feature_importance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 CatBoost Model (Ensemble)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train CatBoost model\n",
    "catboost_model = CatBoostRegressor(\n",
    "    iterations=100,\n",
    "    learning_rate=0.1,\n",
    "    depth=5,\n",
    "    random_state=42,\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "catboost_model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_cat_train = catboost_model.predict(X_train)\n",
    "y_pred_cat_test = catboost_model.predict(X_test)\n",
    "\n",
    "# Evaluation metrics\n",
    "print(\"CatBoost Model Performance:\")\n",
    "print(\"\\nTraining Set:\")\n",
    "print(f\"  MSE: {mean_squared_error(y_train, y_pred_cat_train):.4f}\")\n",
    "print(f\"  RMSE: {np.sqrt(mean_squared_error(y_train, y_pred_cat_train)):.4f}\")\n",
    "print(f\"  MAE: {mean_absolute_error(y_train, y_pred_cat_train):.4f}\")\n",
    "print(f\"  R² Score: {r2_score(y_train, y_pred_cat_train):.4f}\")\n",
    "\n",
    "print(\"\\nTest Set:\")\n",
    "print(f\"  MSE: {mean_squared_error(y_test, y_pred_cat_test):.4f}\")\n",
    "print(f\"  RMSE: {np.sqrt(mean_squared_error(y_test, y_pred_cat_test)):.4f}\")\n",
    "print(f\"  MAE: {mean_absolute_error(y_test, y_pred_cat_test):.4f}\")\n",
    "print(f\"  R² Score: {r2_score(y_test, y_pred_cat_test):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model Comparison and Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare all models\n",
    "results = pd.DataFrame({\n",
    "    'Model': ['Perceptron', 'XGBoost', 'CatBoost'],\n",
    "    'Train_RMSE': [\n",
    "        np.sqrt(mean_squared_error(y_train, y_pred_perceptron_train)),\n",
    "        np.sqrt(mean_squared_error(y_train, y_pred_xgb_train)),\n",
    "        np.sqrt(mean_squared_error(y_train, y_pred_cat_train))\n",
    "    ],\n",
    "    'Test_RMSE': [\n",
    "        np.sqrt(mean_squared_error(y_test, y_pred_perceptron_test)),\n",
    "        np.sqrt(mean_squared_error(y_test, y_pred_xgb_test)),\n",
    "        np.sqrt(mean_squared_error(y_test, y_pred_cat_test))\n",
    "    ],\n",
    "    'Train_R2': [\n",
    "        r2_score(y_train, y_pred_perceptron_train),\n",
    "        r2_score(y_train, y_pred_xgb_train),\n",
    "        r2_score(y_train, y_pred_cat_train)\n",
    "    ],\n",
    "    'Test_R2': [\n",
    "        r2_score(y_test, y_pred_perceptron_test),\n",
    "        r2_score(y_test, y_pred_xgb_test),\n",
    "        r2_score(y_test, y_pred_cat_test)\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(\"Model Comparison:\")\n",
    "print(results)\n",
    "\n",
    "# Visualize comparison\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "results.plot(x='Model', y=['Train_RMSE', 'Test_RMSE'], kind='bar', ax=axes[0], alpha=0.7)\n",
    "axes[0].set_ylabel('RMSE')\n",
    "axes[0].set_title('Model Comparison - RMSE')\n",
    "axes[0].legend(['Train RMSE', 'Test RMSE'])\n",
    "axes[0].set_xticklabels(results['Model'], rotation=0)\n",
    "\n",
    "results.plot(x='Model', y=['Train_R2', 'Test_R2'], kind='bar', ax=axes[1], alpha=0.7)\n",
    "axes[1].set_ylabel('R² Score')\n",
    "axes[1].set_title('Model Comparison - R² Score')\n",
    "axes[1].legend(['Train R²', 'Test R²'])\n",
    "axes[1].set_xticklabels(results['Model'], rotation=0)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction vs Actual plots for all models\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Perceptron\n",
    "axes[0].scatter(y_test, y_pred_perceptron_test, alpha=0.5)\n",
    "axes[0].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "axes[0].set_xlabel('Actual Creatinine')\n",
    "axes[0].set_ylabel('Predicted Creatinine')\n",
    "axes[0].set_title(f'Perceptron\\n(R² = {r2_score(y_test, y_pred_perceptron_test):.4f})')\n",
    "\n",
    "# XGBoost\n",
    "axes[1].scatter(y_test, y_pred_xgb_test, alpha=0.5)\n",
    "axes[1].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "axes[1].set_xlabel('Actual Creatinine')\n",
    "axes[1].set_ylabel('Predicted Creatinine')\n",
    "axes[1].set_title(f'XGBoost\\n(R² = {r2_score(y_test, y_pred_xgb_test):.4f})')\n",
    "\n",
    "# CatBoost\n",
    "axes[2].scatter(y_test, y_pred_cat_test, alpha=0.5)\n",
    "axes[2].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "axes[2].set_xlabel('Actual Creatinine')\n",
    "axes[2].set_ylabel('Predicted Creatinine')\n",
    "axes[2].set_title(f'CatBoost\\n(R² = {r2_score(y_test, y_pred_cat_test):.4f})')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Save Best Model and Predictions for Solution 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select best model based on test R² score\n",
    "best_model_idx = results['Test_R2'].idxmax()\n",
    "best_model_name = results.loc[best_model_idx, 'Model']\n",
    "\n",
    "print(f\"Best Model: {best_model_name}\")\n",
    "print(f\"Test R² Score: {results.loc[best_model_idx, 'Test_R2']:.4f}\")\n",
    "print(f\"Test RMSE: {results.loc[best_model_idx, 'Test_RMSE']:.4f}\")\n",
    "\n",
    "# Select best model predictions\n",
    "if best_model_name == 'Perceptron':\n",
    "    best_predictions = y_pred_perceptron_test\n",
    "    best_model = perceptron_model\n",
    "elif best_model_name == 'XGBoost':\n",
    "    best_predictions = y_pred_xgb_test\n",
    "    best_model = xgb_model\n",
    "else:\n",
    "    best_predictions = y_pred_cat_test\n",
    "    best_model = catboost_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save predictions and additional data needed for Solution 2\n",
    "import pickle\n",
    "\n",
    "# Prepare data for Solution 2\n",
    "solution2_data = {\n",
    "    'X_test': X_test,\n",
    "    'y_test_actual': y_test,\n",
    "    'y_test_predicted': best_predictions,\n",
    "    'best_model_name': best_model_name,\n",
    "    'best_model': best_model,\n",
    "    'scaler': scaler,\n",
    "    'label_encoders': label_encoders,\n",
    "    'df_original': df,\n",
    "    'test_indices': X_test.index\n",
    "}\n",
    "\n",
    "# Save to pickle file\n",
    "with open('solution1_output.pkl', 'wb') as f:\n",
    "    pickle.dump(solution2_data, f)\n",
    "\n",
    "print(\"Data saved successfully for Solution 2!\")\n",
    "print(f\"\\nPredicted Creatinine values (first 10):\")\n",
    "print(best_predictions[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Summary and Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"SOLUTION 1: CREATININE PREDICTION - SUMMARY\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\nDataset Size: {len(df)} samples\")\n",
    "print(f\"Features Used: {len(feature_columns)} features\")\n",
    "print(f\"  - Numeric: Age, Albumin, Urine pH\")\n",
    "print(f\"  - Categorical (encoded): RBC, Pus Cell, Bacteria\")\n",
    "print(f\"\\nTarget Variable: Serum Creatinine (mg/dL)\")\n",
    "print(f\"\\nTrain/Test Split: 80/20\")\n",
    "print(f\"Training Samples: {len(X_train)}\")\n",
    "print(f\"Test Samples: {len(X_test)}\")\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"MODEL PERFORMANCE SUMMARY\")\n",
    "print(\"=\" * 70)\n",
    "print(results.to_string(index=False))\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(f\"BEST MODEL: {best_model_name}\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Test R² Score: {results.loc[best_model_idx, 'Test_R2']:.4f}\")\n",
    "print(f\"Test RMSE: {results.loc[best_model_idx, 'Test_RMSE']:.4f}\")\n",
    "print(\"\\nPredictions saved for Solution 2 (CKD Classification)\")\n",
    "print(\"=\" * 70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
